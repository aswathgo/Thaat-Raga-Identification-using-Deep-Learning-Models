{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb18a2f1-b374-4506-befd-896292b790e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "> pip install gradio\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2c1e0bc-2c76-46d1-8379-fa22ff8ea9ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from pydub import AudioSegment\n",
    "from tqdm import tqdm\n",
    "import librosa\n",
    "import soundfile as sf\n",
    "import os\n",
    "import gc\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import warnings\n",
    "import tensorflow as tf\n",
    "from pytube import YouTube"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5020b1df-ded2-4f1a-a4d9-a4443f961961",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Converting to .wav from .mp3\n",
    "def mp3_to_wav(audio_path):\n",
    "    if \".mp3\" in audio_path:\n",
    "        sound = AudioSegment.from_mp3(audio_path)\n",
    "        sound.export((audio_path[:-3]+\"wav\"), format=\"wav\")\n",
    "        os.remove(audio_path)\n",
    "\n",
    "\n",
    "#Splitting audio into 1 minute length\n",
    "def split_audio(input_audio, input_file, output_dir, chunk_length=60):\n",
    "    y, sr = librosa.load(input_file, sr=None)\n",
    "    num_samples_per_chunk = sr * chunk_length\n",
    "\n",
    "    num_chunks = len(y) // num_samples_per_chunk + 1\n",
    "\n",
    "    for i in range(num_chunks):\n",
    "        start_sample = i * num_samples_per_chunk\n",
    "        end_sample = min((i + 1) * num_samples_per_chunk, len(y))\n",
    "        chunk = y[start_sample:end_sample]\n",
    "        output_file = os.path.join(output_dir, f\"chunk_{i}_{input_audio[:-4]}.wav\")\n",
    "        sf.write(output_file, chunk, sr)\n",
    "        gc.collect()\n",
    "\n",
    "#Extracting spectrogram images\n",
    "def extractor(audio_path,output_dir,name):\n",
    "    y, sr = librosa.load(audio_path)\n",
    "    D = librosa.stft(y)\n",
    "    S_db = librosa.amplitude_to_db(np.abs(D), ref=np.max)\n",
    "    M = librosa.feature.melspectrogram(y=y, sr=sr)\n",
    "    M_db = librosa.power_to_db(M, ref=np.max)\n",
    "    chroma = librosa.feature.chroma_cqt(y=y, sr=sr)\n",
    "    del y; del sr; del D; del M;\n",
    "    gc.collect()\n",
    "\n",
    "    fig, ax = plt.subplots(nrows=3, ncols=1, sharex=True)\n",
    "\n",
    "    img1 = librosa.display.specshow(S_db, x_axis='time', y_axis='log', ax=ax[0])\n",
    "    ax[0].set(title='STFT (log scale)')\n",
    "\n",
    "    img2 = librosa.display.specshow(M_db, x_axis='time', y_axis='mel', ax=ax[1])\n",
    "    ax[1].set(title='Mel Spectrogram')\n",
    "\n",
    "    img3 = librosa.display.specshow(chroma, x_axis='time', y_axis='chroma', key='Eb:maj', ax=ax[2])\n",
    "    ax[2].set(title='Chromagram')\n",
    "\n",
    "    for ax_i in ax:\n",
    "        ax_i.label_outer()\n",
    "\n",
    "    fig.set_figwidth(20)\n",
    "    fig.set_figheight(10)\n",
    "\n",
    "    plt.subplots_adjust()\n",
    "    del S_db; del M_db; del chroma;\n",
    "\n",
    "    fig.savefig(output_dir+f\"\\{name}.png\")\n",
    "    print(\"Saved for \",audio_path)\n",
    "    plt.close()\n",
    "    gc.collect()\n",
    "\n",
    "\n",
    "def download_audio(links, output_folder,name):\n",
    "    if not os.path.exists(output_folder):\n",
    "        os.makedirs(output_folder)\n",
    "\n",
    "    link_no = 0\n",
    "    for link in links:\n",
    "        try:\n",
    "            link_no += 1\n",
    "            yt = YouTube(link)\n",
    "            audio = yt.streams.filter(only_audio=True).first()\n",
    "            print(f\"Downloading:{yt.title}\")\n",
    "            audio.download(output_folder,filename=f\"{name[link_no-1]}.wav\")\n",
    "            print(f\"Downloaded audio from {link}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Failed to download {link}: {str(e)}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40f260a1-c5ce-437c-b323-e40fda4c61a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "# Loading the Models\n",
    "models_path = \" \" #Insert models path here\n",
    "model = load_model(models_path+\"crnn2d_classifier.h5\")\n",
    "\n",
    "models = {}\n",
    "for i in os.listdir(data_dir[0]):\n",
    "    filename = i+\".h5\"\n",
    "    models[i] = load_model(models_path+filename)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23af2ae3-58f6-4b6f-b2e3-1698712fa3ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Class labels\n",
    "thaat_labels = ['Asavari', 'Bhairav', 'Bhairavi','Bilawal','Kafi','Kalyan','Khamaj', 'Marwa', 'Purvi', 'Todi']\n",
    "\n",
    "raag_labels = {\n",
    "    'Asavari': ['Adana', 'Asavari', 'Darbari Kanada', 'Desi', 'Jaunpuri'],\n",
    "    'Bhairav': ['Ahir Bhairav', 'Bairagi', 'Basant Mukhari', 'Bhairav', 'Bhairav Bahar', 'Bibhas', 'Nat Bhairav'],\n",
    "    'Bhairavi': ['Bhairavi', 'Bhupal Todi', 'Bilaskhani Todi', 'Komal Ri Asavari', 'Malkauns'],\n",
    "    'Bilawal': ['Alhaiya Bilawal', 'Bhinna Shadja', 'Bihag', 'Bilaval', 'Durga', 'Hamsadhwani', 'Hemant', 'Pahadi'],\n",
    "    'Kafi': ['Abhogi', 'Bhageshri', 'Gaud Malhar', 'Jog', 'Madhukauns', 'Miyan Malhar', 'Shudh Saarang'],\n",
    "    'Kalyan': ['Bhoopali', 'Hindol', 'Kedar', 'Maru Bihag', 'Shudha Kalyan', 'Yaman Kalyan'],\n",
    "    'Khamaj': ['Desh', 'Jhinjhoti', 'Khamaj', 'Rageshri', 'Sorath'],\n",
    "    'Marwa': ['Bhatiyar', 'Marwa', 'Purba', 'Puriya', 'Sohni'],\n",
    "    'Purvi': ['Basant', 'Deepak', 'Gauri', 'Lalit', 'Puriya Dhanashri', 'Purvi', 'Shree'],\n",
    "    'Todi': ['Gujari Todi', 'Madhuvanti', 'Multani', 'Todi']\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f217c99b-21c1-4a66-8b31-4f8c0ac2cccf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gradio as gr\n",
    "from tensorflow.keras.preprocessing import image\n",
    "import numpy as np\n",
    "import warnings\n",
    "import cv2\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "def predict_raag_from_youtube(link):\n",
    "    output_folder = \" \" #Output folder contains the downloaded audio\n",
    "    download_audio([link], output_folder, [\"temp_audio\"])\n",
    "    input_file = os.path.join(output_folder, \"temp_audio.wav\")\n",
    "    \n",
    "    output_dir = \" \" #Output dir contains extracted spectrogram\n",
    "    extractor(input_file, output_dir, \"temp\")\n",
    "    img_path = os.path.join(output_dir, \"temp.png\")\n",
    "    \n",
    "    img = image.load_img(img_path, target_size=(256, 256))\n",
    "    \n",
    "    x = image.img_to_array(img)\n",
    "    x = np.expand_dims(x, axis=0)\n",
    "    x /= 255.0  # Normalize pixel values to range [0, 1]\n",
    "\n",
    "    thaat_predictions = model.predict(x, verbose=0)\n",
    "    thaat_index = np.argmax(thaat_predictions)\n",
    "    predicted_thaat = thaat_labels[thaat_index]\n",
    "\n",
    "    thaat = 'Thaat_'+predicted_thaat\n",
    "    raag_model = models[thaat]\n",
    "    raag_predictions = raag_model.predict(x, verbose=0)\n",
    "    raag_index = np.argmax(raag_predictions)\n",
    "    predicted_raag = raag_labels[predicted_thaat][raag_index]\n",
    "    \n",
    "   \n",
    "    #os.remove(input_file)\n",
    "    \n",
    "    return predicted_thaat, predicted_raag, img_path"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
